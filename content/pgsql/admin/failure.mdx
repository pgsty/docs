---
title: 故障分析
description: 常见故障与分析排查思路
icon: Wrench
---

本文档列举了 PostgreSQL 和 Pigsty 中可能出现的故障，以及定位，处理，分析问题的 SOP。



## 磁盘空间写满

磁盘空间写满是最常见的故障类型。

#### 现象

当数据库所在磁盘空间耗尽时，PostgreSQL 将无法正常工作，可能出现以下现象：数据库日志反复报错“no space left on device”（磁盘空间不足），
新数据无法写入，甚至 PostgreSQL 可能触发 PANIC 强制关闭。

Pigsty 带有 NodeFsSpaceFull 告警规则，当文件系统可用空间不足 10% 时触发告警。
使用监控系统 NODE Instance 面板查阅 FS 指标面板定位问题。

#### 处理

您也可以登录数据库节点，使用 `df -h` 查看各挂载盘符使用率，确定哪个分区被写满。
对于数据库节点，重点检查以下目录及其大小，以判断是哪个类别的文件占满了空间：

- **数据文件目录**（如 `/pg/data/base`）：存放表和索引的数据文件，若表数据暴增或出现未清理的大量临时文件，可能导致占满。
- **WAL 日志目录**（如 `pg/data/pg_wal`）：存放预写日志(WAL)，WAL 堆积/复制槽保留 是常见的磁盘写满原因。
- **数据库日志目录**（如 `pg/log`）：如果 PostgreSQL 日志未及时轮转写大量报错写入，长期累积也可能占用大量空间。
- **本地备份目录**（如 `data/backups`）：使用 pgBackRest 等在本机保存备份时，备份文件增多也可能撑满磁盘。

如果问题出在 Pigsty 管理节点或监控节点，还需考虑：

- **监控数据**：Prometheus 的时间序列指标存储和 Loki 的日志存储都会占用磁盘。如果监控数据未设置合理保留策略，长期堆积可能写满磁盘。
- **对象存储数据**：Pigsty 集成的 MinIO 对象存储用于保存备份和业务上传文件，若其中存放了大量备份文件或大体积数据，也可能使管理节点磁盘告急。

明确占用空间最大的目录后，可进一步使用 `du -sh <目录>` 深入查找特定大型文件或子目录。

### 处理

磁盘写满属于紧急问题，需立即采取措施释放空间并保证数据库继续运行：

- **WAL 日志占满**：这是最危险的情况，因为 WAL 无法写入会阻断所有事务。应首先检查归档进程状态：若 `archive_command` 失败导致 WAL 无法归档删除，立即修复归档命令或暂时关闭归档以允许数据库自动清理旧 WAL。紧急情况下，可将旧的 WAL 文件临时移动到其他挂载点（注意保留备份），腾出空间后尽快让归档恢复正常。
- **数据文件占满**：如果是表数据增长导致，用空间管理策略。短期可考虑删除无用的大表或临时数据、清理长时间未使用的临时文件。中长期应考虑扩容：增加磁盘配额或将大型表迁移到新的表空间/磁盘分区。确保监控表大小增长趋势，提前扩容避免再度触顶。
- **日志文件占满**：立即压缩或清理历史日志文件。开启 PostgreSQL 日志轮换（如设置 `log_rotation_size` 和 `log_rotation_age`）以防止日志无限增长。对 Loki 日志存储，调整保留时间或大小限制，删除过旧的日志数据。
- **备份文件占满**：如果本地备份太多，删除过期的备份集以释放空间（保证至少保留必要的备份周期）。考虑将备份存储迁移到异地，例如使用远程对象存储（Pigsty 中的 MinIO 或 S3）并在本地只保留最近的备份。确保备份策略规定定期清理旧备份，避免占满本地磁盘。
- **监控数据占满**：为 Prometheus 设置合理的数据保留期限，或者启用联邦/远端存储将历史长周期数据迁出。Loki 日志亦应配置日志保留策略，定期清理过旧日志。若管理节点磁盘空间不足，可扩容监控节点存储或将部分监控组件的数据目录挂载独立的大盘符。

**紧急情况**：当数据盘并未与系统盘区分时，写满磁盘可能导致 Shell 命令无法执行。这种情况下，可以删除 `/pg/dummy` 占位文件，释放少量应急空间以便 shell 命令恢复正常。

采取上述措施释放出空间后，PostgreSQL 应能恢复正常运行。如果数据库由于 pg_wal 写满已经宕机，清理空间后需要重启数据库服务并仔细检查数据完整性。






## 事务号回卷

PostgreSQL 循环使用 32 位事务ID (XID) 计数事务，每当事务ID即将耗尽时，会出现“事务号回卷”故障（XID Wraparound）。

#### 现象

第一阶段的典型征兆是 [PGSQL Persist - Age Usage](https://g.pgsty.com/d/pgsql-persist) 面板年龄饱和度进入警告区域。
数据库日志开始出现：`WARNING: database "postgres" must be vacuumed within xxxxxxxx transactions` 字样的信息。

若问题持续恶化，PostgreSQL 会进入保护模式：当剩余事务ID不到约100万时数据库切换为只读模式；达到上限约21亿（2^31）时则拒绝任何新事务并迫使服务器停机以避免数据错误。

#### 诊断

PostgreSQL 与 Pigsty 默认启用自动垃圾回收（AutoVacuum），因此此类故障出现通常有更深层次的根因。
常见的原因包括：超长事务（SAGE），Autovacuum 配置失当，复制槽阻塞，资源不足，存储引擎/扩展BUG，磁盘坏快。

首先定位年龄最大的数据库，然后可通过 Pigsty PGCAT Database - Tables 面板来确认表的年龄分布。
同时查阅数据库错误日志，通常可以找到定位根因的线索。


#### 处理

1. **立即冻结老事务**：如果数据库尚未进入只读保护状态，立刻对受影响的库执行一次手动 VACUUM FREEZE。可以从老化最严重的表开始逐个冻结，而不是整库一起做，以加快效果。使用超级用户连接数据库，针对识别出的 `relfrozenxid` 最大的表运行 `VACUUM FREEZE 表名;`，优先冻结那些XID年龄最大的表元组。这样可以迅速回收大量事务ID空间。
2. **单用户模式救援**：如果数据库已经拒绝写入或宕机保护，此时需要启动数据库到单用户模式执行冻结操作。在单用户模式下运行 `VACUUM FREEZE database_name;` 对整个数据库进行冻结清理。完成后再以多用户模式重启数据库。这样做可以解除回卷锁定，让数据库重新可写。需要注意在单用户模式下操作要非常谨慎，并确保有足够的事务ID余量完成冻结。
3. **备用节点接管**：在某些复杂场景（例如遭遇硬件问题导致 vacuum 无法完成），可考虑提升集群中的只读备节点为主，以获取一个相对干净的环境来处理冻结。例如主库因坏块导致无法 vacuum，此时可以手动Failover提升备库为新的主库，再对其进行紧急 vacuum freeze。确保新主库已冻结老事务后，再将负载切回来。这一措施需要在 Patroni 控制的集群中小心进行，必要时暂停自动故障转移，手动提升节点并同步。








## 连接耗尽

PostgreSQL 有一个最大连接数配置 (`max_connections`)，当客户端连接数超过此上限时，新的连接请求将被拒绝。典型现象是在应用端看到数据库无法连接，并报出类似
**FATAL: remaining connection slots are reserved for non-replication superuser connections** 或 **too many clients already** 的错误。
这表示普通连接数已用完，仅剩下保留给超管或复制的槽位

#### 诊断

连接耗尽通常由客户端大量并发请求引起。诊断步骤：

- **确认连接数与上限**：首先通过 `SHOW max_connections;` 或监控面板确认 max_connections 当前大小，以及当前连接总数是否达到或超过此值（超管保留部分除外）。如果连接数确实打满，则确定这是连接耗尽问题。
- **检查连接来源**：查询 `pg_stat_activity`，按应用名或客户端地址统计连接数，找出主要的连接来源。例如某个应用服务可能意外创建了过多连接未释放，或者某一批作业并发启动导致瞬间连接激增。定位到具体来源后可进一步分析原因。
- **区分连接状态**：观察 `pg_stat_activity` 中连接的状态，有多少是 active，多少是 idle（空闲）。如果大量连接长期处于 idle 状态，可能表示应用没有及时关闭连接，存在连接泄漏。如果大部分连接都繁忙 active，则可能是流量高峰真的需要这么多并发处理。
- **应用连接池使用情况**：检查应用是否使用了连接池，如 PgBouncer、HikariCP 等。如果没有使用，应用可能每次请求都直接连接数据库，导致连接数飙升。即便使用了，也要看池配置是否合理，例如池大小是否过大或者pool未开启复用。
- **服务器资源检查**：评估数据库服务器CPU和内存使用率。当连接数过多时，上下文切换和内存开销都会上升。如果发现 CPU 满载或发生 SWAP，说明服务器已经不堪重负。特别是如果曾尝试提高 max_connections 导致服务器出现性能问题，则要注意**过多连接带来的效率下降**[dba.stackexchange.com](https://dba.stackexchange.com/questions/120694/postgresql-remaining-connection-slots-are-reserved-for-non-replication-superuse#:~:text=Use PgBouncer in transaction,in pooling)。PostgreSQL 并不擅长处理成百上千的活跃连接，通常上百连接就可能严重影响性能。
- **特殊连接占用**：确认是否有某些连接未正常退出（例如僵尸进程持有连接）或者存在事务一直占用着连接（类似 idle in transaction）。这些情况会占用连接槽且不做工作，需要识别并清理。

通过以上检查，明确是纯粹的高并发需求导致连接打满，还是异常情况（如连接泄漏或配置不当）导致的耗尽。

#### 处理

根据诊断结果，可采取以下最佳实践来解决连接耗尽：

- **短期缓解**：对于已经耗尽导致业务受阻的情况，需先释放部分连接槽位。可以优先终止那些长时间空闲或明显异常的会话（使用 `pg_terminate_backend(pid)`）。对于有大量 idle 但未断开的连接，会断掉后端并让应用重连获取连接。但要谨慎，不要误杀正在执行关键事务的连接。在紧急情况下，通过PgBouncer的admin接口设置最大连接或暂停接受新连接，也可防止进一步恶化。
- **使用连接池**：从根本上解决，**引入连接池中间件**。大量并发应用不应直接建立等量的数据库连接，而应该通过连接池复用有限的连接资源[dba.stackexchange.com](https://dba.stackexchange.com/questions/120694/postgresql-remaining-connection-slots-are-reserved-for-non-replication-superuse#:~:text=,need a connection pool)。Pigsty 已经集成了 PgBouncer 作为连接池组件，建议开启并让应用连接 PgBouncer 而非直接连 Postgres。合理配置池大小（例如几十而不是几百），让池来队列化请求，从而把数据库的实际连接数控制在可管理范围。正如经验所示，成百上千连接对Postgres效率有害，利用连接池将并发请求序列化，可以减轻数据库负载[dba.stackexchange.com](https://dba.stackexchange.com/questions/120694/postgresql-remaining-connection-slots-are-reserved-for-non-replication-superuse#:~:text=Use PgBouncer in transaction,in pooling)。
- **优化应用连接管理**：确保应用层正确使用连接池或驱动的连接复用机制。检查应用代码，避免频繁打开新连接却不关闭。例如在 Java 中使用 HikariCP 等，配置最大连接数略小于数据库 max_connections。对于 Golang/Python 等，也有类似池机制。应用应做到**不使用时及时释放连接**，避免“用完不管”的泄漏。定期在应用侧打印连接池使用情况，及时发现异常增长。
- **调整数据库连接上限**：在使用连接池并优化后，如果的确有更高的并发需求且服务器资源允许，可以考虑适当调高 PostgreSQL 的 max_connections。但每增加连接上限，都要相应增加服务器内存（每连接约消耗数MB）和内核文件句柄限制。一般不建议将 max_connections 提到非常大（比如上千）[dba.stackexchange.com](https://dba.stackexchange.com/questions/120694/postgresql-remaining-connection-slots-are-reserved-for-non-replication-superuse#:~:text=,for such a small server)。如果需求超过单机承载，应该考虑水平扩展（读写分离，增加只读节点分摊查询）而非无限堆高连接数。
- **预留超管连接**：确保 PostgreSQL 参数 `superuser_reserved_connections` 保留了足够的超管连接数（默认3）。这样即便普通连接占满，DBA 仍能以超级用户连接进去排查问题。在Pigsty环境下，也要保证监控或管理脚本的连接（通常使用超管角色）有保留槽可用。
- **监控与报警**：将数据库当前连接数占 max_connections 比例加入监控，并设置阈值报警（例如超过80%告警）。当连接逼近上限时提前通知运维，以便及时采取措施（比如临时扩容池或排查业务异常）。Pigsty 默认监控包含了 `pg_connections` 相关指标，应充分利用。
- **防止雪崩**：连接耗尽有时是**结果**不是原因，例如慢查询堆积引发大量新连接尝试（见下节“慢查询堆积雪崩”）。因此处理连接耗尽的同时，要留意是否存在导致连接猛增的根本原因并一并解决，如上游重试风暴、查询卡顿等，以避免治标不治本。

通过以上措施，建立起稳定的连接管理机制。总的指导思想是：尽量**少而复用**数据库连接，以发挥PostgreSQL最大性能和稳定性。一旦应用并发增长超出单库承载，则考虑架构层面的拆分或扩容，而非简单堆砌连接数。




## 修改配置后无法启动

现象：修改 PostgreSQL 集群配置后，重启失败，数据库集群无法启动。


## 慢查询堆积雪崩



## etcd 配额写满



## 有缺陷的存储引擎

目前，TimescaleDB 的试验性存储引擎 Hypercore 被证实存在缺陷，已经出现 VACUUM 无法回收出现 XID 回卷故障的案例。
请使用该功能的用户及时迁移至普通

请避免在生产环境，关键任务中使用未经长时间可靠验证的新存储引擎。

详细介绍：《[PG新存储引擎故障案例](https://mp.weixin.qq.com/s/LdZVVyOj4BA9C892I25lQw)》

